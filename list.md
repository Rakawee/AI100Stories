- 人工智能（AI - Artificial Intelligence）：计算机科学的一个领域，专注于创建能够执行传统上需要人类智能的任务的系统，例如学习、推理、决策和语言理解。
- 通用人工智能（AGI - Artificial General Intelligence）：一种理论上的人工智能形式，能够理解、学习和应用知识于任何智力任务，达到或超过人类的认知能力。
- 算法（Algorithm）：为执行特定任务（例如计算和数据分析）而设计的一组指令或规则，通常使用计算机或其他智能设备。
- 符号人工智能（Symbolic AI）：一种人工智能方法，它基于对问题、逻辑和搜索的明确人类可读表示（符号）进行操作，与基于统计学习的连接主义方法相对。
- 神经符号人工智能（NSAI - Neuro-symbolic AI）：一种结合了神经网络（神经）和符号推理（符号）方法的人工智能，旨在利用两者的优势，实现更强大、可解释和可泛化的智能系统。
- 知识表示（KR - Knowledge Representation）：在人工智能中，以计算机可处理的形式对知识进行编码和结构化的过程，以便系统能够进行推理和决策。
- 本体（Ontology）：对特定领域中概念、属性及其相互关系的明确、形式化的规范说明，常用于构建知识库和知识图谱。
- 知识图谱（KG - Knowledge Graph）：一种以图形结构表示实体及其之间复杂关系的知识库，其中节点代表实体或概念，边代表它们之间的关系。
- 机器学习（ML - Machine Learning）：人工智能的一个子领域，专注于开发使计算机能够从数据中学习并做出预测或决策的算法和模型。
- 监督学习（Supervised Learning）：一种机器学习方法，其中模型从包含输入-输出对的标记数据集中学习，目标是学习一个映射函数，以便对新的未见输入进行预测。
- 无监督学习（Unsupervised Learning）：一种机器学习方法，其中模型从未标记的数据中学习，目标是发现数据中潜在的模式或结构，如聚类或降维。
- 强化学习（RL - Reinforcement Learning）：机器学习的一种类型，其中智能体通过与环境交互并根据获得的奖励或惩罚来学习采取最大化累积奖励的行动。
- 自监督学习（SSL - Self-Supervised Learning）：一种机器学习范式，模型从未标记数据中自动生成标签或监督信号进行学习，通常通过解决预设的辅助任务来实现。
- 零样本学习（ZSL - Zero-Shot Learning）：机器学习中的一种学习范式，模型能够在没有见过任何特定类别样本的情况下识别这些新类别，通常通过利用辅助信息（如属性或文本描述）来实现。
- 少样本学习（FSL - Few-Shot Learning）：机器学习中的一种学习范式，模型被设计为能够从极少数（例如，一到五个）标记样本中学习并泛化到新的、未见过的类别或任务。
- 迁移学习（TL - Transfer Learning）：机器学习中的一种技术，将在一个任务上学到的知识或模型应用于另一个不同但相关的任务，从而减少对大量标记数据的需求并加速学习过程。
- 元学习（Meta-learning）：机器学习的一个子领域，专注于设计能够从少量数据或先前任务经验中快速学习新任务的算法，即"学会学习"。
- 联邦学习（FL - Federated Learning）：一种分布式机器学习技术，允许多个参与方在不共享其本地私有数据的情况下协同训练一个共享模型，从而保护数据隐私。
- 集成学习（Ensemble Learning）：一种机器学习范式，通过构建并结合多个学习器（模型）的预测来获得比单个学习器更好的性能。
- 决策树（DT - Decision Tree）：一种监督学习算法，通过构建树状决策模型来进行分类或回归，其中每个内部节点表示对一个属性的测试，每个分支代表测试结果，每个叶节点代表一个类别标签或数值。
- 支持向量机（SVM - Support Vector Machine）：一种监督学习算法，通过在特征空间中找到一个最优超平面来进行分类或回归，该超平面能够最大化不同类别样本之间的间隔。
- K近邻算法（KNN - K-Nearest Neighbors）：一种非参数的监督学习算法，通过查找训练集中与新样本最相似的K个邻居，并根据这些邻居的类别或值来进行分类或回归。
- 聚类（Clustering）：无监督学习中的一项任务，旨在将数据集中的样本根据其相似性划分为若干个组（簇），使得同一簇内的样本相似度较高，不同簇间的样本相似度较低。
- 降维（Dimensionality Reduction）：在机器学习中，减少数据集中特征（维度）数量的过程，同时尽可能保留重要信息，以简化模型、减少计算量或可视化数据。
- 主成分分析（PCA - Principal Component Analysis）：一种常用的无监督降维技术，通过线性变换将原始数据投影到一组新的正交坐标轴（主成分）上，使得数据在这些新轴上的方差最大化。
- 深度学习（DL - Deep Learning）：机器学习的一个子领域，涉及具有许多层（深度神经网络）的神经网络，在图像和语音识别等任务中非常成功。
- 人工神经网络（ANN - Artificial Neural Network）：一种受生物大脑启发的计算结构，由大量相互连接的计算单元（"神经元"）组成，这些单元分层连接，用于处理数据和识别模式。
- 卷积神经网络（CNN - Convolutional Neural Network）：一种特殊类型的深度神经网络，特别适用于处理网格状拓扑数据（如图像），通过卷积层自动学习空间层次结构中的特征。
- 循环神经网络（RNN - Recurrent Neural Network）：一种能够处理序列数据（如文本或时间序列）的神经网络，其连接在节点之间形成有向图，允许信息在时间步之间持续存在。
- 长短期记忆网络（LSTM - Long Short-Term Memory）：一种特殊的循环神经网络（RNN），通过引入门控机制来解决传统RNN中的梯度消失和梯度爆炸问题，从而能够学习长期依赖关系。
- 门控循环单元（GRU - Gated Recurrent Unit）：一种循环神经网络（RNN）的门控机制，类似于LSTM，但结构更简单，旨在捕捉序列数据中的依赖关系。
- Transformer模型（Transformer）：一种基于自注意力机制的深度学习模型架构，特别擅长处理序列数据，已成为自然语言处理领域的主流模型。
- 注意力机制（Attention Mechanism）：深度学习中的一种机制，允许模型在处理输入序列时动态地关注信息最相关的部分，从而提高性能，尤其在长序列任务中。
- 生成对抗网络（GAN - Generative Adversarial Network）：一种由两个神经网络（生成器和判别器）组成的深度学习架构，它们通过相互竞争来生成逼真的新数据样本。
- 自编码器（AE - Autoencoder）：一种无监督学习的神经网络，通过将输入数据编码为低维表示然后再解码重构原始输入，用于特征学习或降维。
- 扩散模型（Diffusion Models）：一类生成模型，通过模拟数据点逐渐扩散到噪声的过程，然后学习逆转此过程以从噪声生成新数据样本。
- 胶囊网络（CapsNet - Capsule Network）：一种旨在克服卷积神经网络某些局限性（如对输入变换的敏感性）的新型神经网络架构，通过使用"胶囊"来表示和学习分层姿态信息。
- 激活函数（Activation Function）：在人工神经网络中，决定神经元是否应该被激活（即传递信号）的函数，它为网络引入非线性，使其能够学习复杂模式。
- 反向传播（Backpropagation）：训练人工神经网络时常用的一种算法，通过计算损失函数相对于网络权重的梯度，并从输出层反向传播这些梯度来更新权重，以最小化误差。
- 梯度下降（GD - Gradient Descent）：一种优化算法，用于通过迭代地在损失函数梯度的负方向上调整模型参数来最小化损失函数。
- 损失函数/代价函数（Loss Function / Cost Function）：在机器学习中，衡量模型预测值与真实值之间差异的函数，优化算法的目标是最小化这个函数的值。
- Dropout/随机失活（Dropout）：深度学习中一种正则化技术，在训练过程中以一定概率随机"丢弃"神经网络中的单元及其连接，以防止过拟合。
- 批量归一化（BN - Batch Normalization）：深度学习中一种用于加速训练和提高模型稳定性的技术，通过对每个小批量数据在网络层间的激活值进行归一化处理。
- 正则化（Regularization）：在机器学习中用于防止过拟合的一系列技术，通过向损失函数添加惩罚项来约束模型复杂度。
- 过拟合（Overfitting）：机器学习模型在训练数据上表现良好，但在未见过的测试数据上表现差的现象，通常因为模型过于复杂或训练数据不足。
- 欠拟合（Underfitting）：机器学习模型未能很好地捕捉训练数据中的潜在模式，导致在训练数据和测试数据上均表现不佳的现象，通常因为模型过于简单。
- 超参数（Hyperparameter）：在机器学习模型开始训练之前设置的参数，用于控制学习过程本身，例如学习率、批量大小或网络层数。
- 微调（Fine-Tuning）：将在一个大型通用数据集上预训练好的模型，在一个较小的、特定任务的数据集上进行进一步训练以适应特定需求的过程。
- 预训练模型（Pre-trained Model）：已经在一个大规模数据集上训练过的模型，可以作为解决特定任务的起点，通过微调等方式适应新任务。
- 数据增强（Data Augmentation）：一种通过对现有训练数据进行变换（如旋转、裁剪图像或同义词替换文本）来人工增加训练数据集大小和多样性的技术，以提高模型泛化能力。
- 自然语言处理（NLP - Natural Language Processing）：人工智能的一个分支，专注于使计算机能够理解、解释和生成人类语言，用于聊天机器人、翻译和情感分析等应用。
- 自然语言理解（NLU - Natural Language Understanding）：自然语言处理的一个子领域，专注于使计算机能够理解和解释人类语言的含义、意图和上下文。
- 自然语言生成（NLG - Natural Language Generation）：自然语言处理的一个子领域，专注于从结构化数据或非语言输入中自动生成人类可读的文本或语音。
- 大型语言模型（LLM - Large Language Models）：在大量文本数据上训练的深度学习模型，能够理解、生成和操作人类语言，用于问答、翻译和内容创作等任务。
- BERT模型（BERT - Bidirectional Encoder Representations from Transformers）：一种基于Transformer架构的预训练语言模型，通过双向编码器表示来理解文本上下文，在多种自然语言处理任务中取得了显著成果。
- GPT模型（GPT - Generative Pre-trained Transformer）：一系列基于Transformer架构的生成式预训练语言模型，擅长生成连贯且与上下文相关的文本。
- 分词/词元化（Tokenization）：在自然语言处理中，将文本序列（如句子或段落）分割成更小的单元（称为词元或token，如单词、子词或字符）的过程。
- 嵌入（Embedding）：在机器学习和自然语言处理中，将高维离散特征（如单词、实体）映射到低维连续向量空间的过程，使得相似的项在向量空间中距离更近。
- Word2Vec（Word2Vec）：一组用于从原始文本生成词嵌入（word embeddings）的相关模型，它能够捕捉词语之间的语义关系。
- 命名实体识别（NER - Named Entity Recognition）：自然语言处理中的一项任务，旨在识别文本中具有特定意义的实体（如人名、地名、组织名、日期等）并将其分类。
- 词性标注（POS Tagging - Part-of-Speech Tagging）：在自然语言处理中，为文本中的每个词语分配其对应的词法类别（如名词、动词、形容词等）的过程。
- 句法分析（Parsing / Syntactic Analysis）：在自然语言处理中，分析句子的语法结构并将其表示为树状结构（句法树）的过程，以揭示词语之间的依赖关系。
- 语义分析（Semantic Analysis）：自然语言处理中的一个阶段，专注于理解文本的含义，超越单个词语的字面意思，考虑词语组合、上下文和语用信息。
- 情感分析（Sentiment Analysis）：使用自然语言处理、文本分析和计算语言学等方法，识别和提取文本材料中主观信息（如观点、情感、评价）的过程。
- 机器翻译（MT - Machine Translation）：利用计算机程序自动将一种自然语言的文本或语音转换为另一种自然语言的过程。
- 语料库（Corpus）：在语言学和自然语言处理中，指经过收集、组织和标注的大量真实文本或语音数据集合，用于语言研究和模型训练。
- 计算机视觉（CV - Computer Vision）：人工智能的一个领域，专注于使计算机能够从图像和视频等视觉输入中解释和理解信息，并据此采取行动或提出建议。
- 图像识别（Image Recognition）：计算机视觉中的一项任务，旨在识别和分类图像中的物体、场景或特定模式。
- 物体检测/目标检测（Object Detection）：计算机视觉中的一项任务，不仅要识别图像中的物体类别，还要定位物体在图像中的位置（通常通过边界框）。
- 图像分割（Image Segmentation）：计算机视觉中的一项任务，将数字图像划分为多个片段（像素集），旨在简化或改变图像的表示形式，使其更有意义且更易于分析。
- 光学字符识别（OCR - Optical Character Recognition）：将图像中的打印或手写文本转换为机器可编辑文本的过程。
- 生成式人工智能（GenAI - Generative AI）：一类人工智能，专注于根据其训练数据创建新的原创内容，如文本、图像、音频或视频。
- 基础模型（Foundation Models）：在大量未标记数据上进行预训练的大型人工智能模型，可以适应广泛的下游任务，如GPT系列模型。
- 聊天机器人（Chatbot）：一种设计用于通过文本或语音交互模拟人类对话的人工智能程序，通常使用自然语言处理技术。
- 提示工程（Prompt Engineering）：设计和优化输入提示（prompts）以指导生成式人工智能模型（如大型语言模型）产生期望或高质量输出的过程。
- 基于人类反馈的强化学习（RLHF - Reinforcement Learning from Human Feedback）：一种训练人工智能模型（尤其是大型语言模型）的技术，通过结合人类对模型输出的偏好反馈来优化模型的行为，使其更符合人类期望。
- 人工智能幻觉（Hallucination in AI）：人工智能模型（尤其是生成式模型）产生看似合理但实际上是错误、无意义或与输入数据不符的输出的现象。
- 机器人学（Robotics）：一个跨学科领域，涉及机器人的设计、构造、操作和使用，这些机器人能够自主或半自主地在物理世界中执行任务。
- 专家系统（ES - Expert Systems）：旨在模拟特定领域人类专家决策能力的人工智能系统，通常使用知识库和推理引擎。
- 自主系统（Autonomous Systems）：能够在没有人为干预的情况下独立运行、感知环境、做出决策并执行任务的系统。
- 世界模型（WM - World Models）：在强化学习和人工智能中，指智能体学习到的关于其环境动态的内部表征或模型，使其能够预测未来状态并进行规划或决策。
- 量子人工智能（QAI - Quantum AI）：一个新兴的跨学科领域，探索如何利用量子计算的原理来增强人工智能和机器学习算法的能力。
- 边缘人工智能（Edge AI）：一种在边缘设备（如智能手机、传感器或物联网设备）上本地运行人工智能算法的技术，而不是在集中的云服务器上，从而减少延迟、提高隐私并节省带宽。
- 大数据（Big Data）：指体量巨大、复杂多样的数据集，传统的数据库管理工具难以处理，需要新的算法进行存储、分析和分类以揭示模式和趋势。
- 数据挖掘（Data Mining）：从大量数据中发现有用模式、趋势和知识的过程，通常用于支持决策。
- 特征提取（Feature Extraction）：在机器学习和模式识别中，从原始数据中转换或选择出一组更具信息量、更易于处理的特征的过程，以提高模型性能。
- 特征工程（Feature Engineering）：利用领域知识从原始数据中创造、选择和转换特征的过程，旨在提高机器学习模型的性能。
- 模型评估（Model Evaluation）：在机器学习中，使用各种指标（如准确率、精确率、召回率、F1分数等）来衡量已训练模型在未见过数据上的性能和泛化能力的过程。
- 交叉验证（Cross-Validation）：一种模型评估技术，将原始数据集分割成多个子集，轮流使用一部分子集作为训练数据，其余子集作为验证数据，以更稳健地评估模型性能。
- 准确率（Accuracy）：在分类任务中，模型正确预测的样本数占总样本数的比例。
- 精确率/查准率（Precision）：在二分类任务中，模型预测为正例的样本中，实际也为正例的比例。
- 召回率/查全率（Recall / Sensitivity）：在二分类任务中，实际为正例的样本中，被模型正确预测为正例的比例。
- F1分数（F1 - F1-Score）：精确率和召回率的调和平均数，用于综合评估二分类模型的性能。
- 混淆矩阵（Confusion Matrix）：在监督学习中，一种可视化分类模型性能的表格，显示了模型预测类别与实际类别之间的对应关系。
- ROC曲线（ROC - Receiver Operating Characteristic Curve）：在二分类任务中，以假正例率（FPR）为横轴，真正例率（TPR，即召回率）为纵轴绘制的曲线，用于评估模型在不同阈值下的性能。
- AUC值（AUC - Area Under the ROC Curve）：ROC曲线下的面积，是衡量二分类模型整体性能的一个常用指标，值越接近1表示模型性能越好。
- 人工智能伦理（AI Ethics）：应用伦理学的一个分支，研究与人工智能系统的设计、开发和部署相关的道德问题、原则和最佳实践。
- 人工智能偏见（Bias in AI）：人工智能系统中存在的系统性错误或不公平结果，通常源于有偏见的训练数据或算法设计缺陷，可能导致对特定群体的歧视。
- 可解释人工智能（XAI - Explainable AI）：一套旨在使人工智能系统的决策过程和输出结果能够被人类理解、信任和有效管理的技术和方法。
- 人在回路（HITL - Human-in-the-Loop）：一种将人类智能与人工智能系统相结合的模型，人类在模型的训练、验证或决策过程中扮演关键角色，以提高系统性能、处理模糊情况或确保伦理合规。